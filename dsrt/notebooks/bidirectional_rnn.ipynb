{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The bi-directional RNN that will form the basis of all our future dialogue\n",
    "models.\n",
    "\n",
    "The goal is to create a bi-directional encoder-decoder that can be either used independently\n",
    "for next-response generation, or integrated into a hierarchical (or more complicated)\n",
    "model.\n",
    "\n",
    "To that end, the BidirectionalRNN class should should support the same interface as our\n",
    "other dialogue models: it should take a Config() object, it should take a DialogueCorpus()\n",
    "object, and it should support the same fit() and predict() methods that (along with SciPy\n",
    "classifiers) all our models support.\n",
    "\"\"\"\n",
    "\n",
    "# Keras packages\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, GRU, Dense, Bidirectional\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import re\n",
    "\n",
    "# Our packages\n",
    "from config import Config\n",
    "from dialogue_corpus import DialogueCorpus\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, data, config=Config()):\n",
    "        self.config = config\n",
    "        self.data = data\n",
    "        \n",
    "        self.build() # this will be a Keras model for now\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        The encoder computational graph consists of three components:\n",
    "        (1) the input node            `encoder_input`\n",
    "        (2) the Recurrent part        `encoder_rnn`\n",
    "        (3) the hidden state output   `encoder_hidden_state`\n",
    "        \"\"\"\n",
    "        \n",
    "        # Grab hyperparameters from self.config:\n",
    "        hidden_dim = self.config['encoding-layer-width']\n",
    "        recurrent_unit = self.config['recurrent-unit-type']\n",
    "        bidirectional = False # self.config['encoding-layer-bidirectional']\n",
    "        vocab_size = self.data.vocab_size\n",
    "        embedding_dim = math.ceil(math.log(vocab_size, 2))    # self.config['embedding-dim']\n",
    "        input_length = self.data.max_utterance_length + 1\n",
    "        \n",
    "        # Assemble the network components:\n",
    "        encoder_input = Input(shape=(None,))\n",
    "        encoder_embed = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_input) #, input_length=input_length)(encoder_input)\n",
    "        # input of this Embedding() is  (None, input_length)\n",
    "        # output of this Embedding() is (None, input_length, embedding_dim)\n",
    "        encoder_rnn, encoder_hidden_state = None, None\n",
    "        \n",
    "        if recurrent_unit == 'lstm':\n",
    "            encoder_rnn = LSTM(hidden_dim, return_state=True)\n",
    "            encoder_output, encoder_state_h, encoder_state_c = encoder_rnn(encoder_embed)\n",
    "            # discard the encoder output, keeping only the hidden state\n",
    "            encoder_hidden_state = [encoder_state_h, encoder_state_c]\n",
    "        if recurrent_unit == 'gru':\n",
    "            encoder_rnn = GRU(hidden_dim, return_state=True)\n",
    "            encoder_output, encoder_hidden_state = encoder_rnn(encoder_embed)\n",
    "        else:\n",
    "            raise Exception('Invalid recurrent unit type: {}'.format(recurrent_unit))\n",
    "        \n",
    "        # make the RNN component bidirectional, if desired\n",
    "        if bidirectional:\n",
    "            encoder_rnn = Bidirectional(encoder_rnn, merge_mode='ave')\n",
    "        \n",
    "        # save the three Enccoder components as class state\n",
    "        self.encoder_input = encoder_input\n",
    "        self.encoder_embed = encoder_embed\n",
    "        self.encoder_rnn = encoder_rnn\n",
    "        self.encoder_hidden_state = encoder_hidden_state\n",
    "        \n",
    "        # finally, build the training model\n",
    "        self.training_model = Model(self.encoder_input, self.encoder_hidden_state)\n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "        \n",
    "class Decoder:\n",
    "    def __init__(self, data, encoder, config=Config()):\n",
    "        self.config = config\n",
    "        self.data = data\n",
    "        self.encoder = encoder\n",
    "        \n",
    "        self.build() # this will be a Keras model for now\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        The decoder computational graph consists of three components:\n",
    "        (1) the input node            `decoder_input`\n",
    "        (2) the Recurrent part        `decoder_rnn`\n",
    "        (3) the decoder output        `decoder_output`\n",
    "        \"\"\"\n",
    "        \n",
    "        # Grab hyperparameters from self.config:\n",
    "        hidden_dim = self.config['encoding-layer-width']\n",
    "        recurrent_unit = self.config['recurrent-unit-type']\n",
    "        bidirectional = False #self.config['encoding-layer-bidirectional']\n",
    "        vocab_size = self.data.vocab_size\n",
    "        embedding_dim = math.ceil(math.log(vocab_size, 2))    # self.config['embedding-dim']\n",
    "        input_length = self.data.max_utterance_length + 1\n",
    "        \n",
    "        # Assemble the network components:\n",
    "        decoder_input = Input(shape=(None,))\n",
    "        decoder_embed = Embedding(vocab_size, embedding_dim, mask_zero=True)(decoder_input) #, input_length=input_length)(decoder_input)\n",
    "        \n",
    "        if recurrent_unit == 'lstm':\n",
    "            decoder_rnn = LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
    "            decoder_output, decoder_h, decoder_c = decoder_rnn(decoder_embed,\n",
    "                                                initial_state=self.encoder.encoder_hidden_state)\n",
    "        elif recurrent_unit == 'gru':\n",
    "            decoder_rnn = GRU(hidden_dim, return_sequences=True, return_state=True)\n",
    "            decoder_output, _ = decoder_rnn(decoder_embed, \n",
    "                                             initial_state=self.encoder.encoder_hidden_state)\n",
    "        else:\n",
    "            raise Exception('Invalid recurrent unit type: {}'.format(recurrent_unit))\n",
    "        \n",
    "        # make the RNN component bidirectional, if desired\n",
    "        if bidirectional:\n",
    "            decoder_rnn = Bidirectional(decoder_rnn, merge_mode='ave')\n",
    "        \n",
    "        decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "        decoder_output = decoder_dense(decoder_output)\n",
    "        \n",
    "        # save the four Decoder components as class state\n",
    "        self.decoder_input = decoder_input\n",
    "        self.decoder_embed = decoder_embed\n",
    "        self.decoder_rnn = decoder_rnn\n",
    "        self.decoder_dense = decoder_dense\n",
    "        self.decoder_output = decoder_output\n",
    "        \n",
    "        return\n",
    "\n",
    "    \n",
    "class EncoderDecoder:\n",
    "    def __init__(self, data, encoder, decoder, config=Config()):\n",
    "        self.config = config\n",
    "        self.data = data\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        # build the trainin and inference models; save them\n",
    "        self.build_training_model()\n",
    "        self.build_inference_model()\n",
    "        \n",
    "        self.save_models()\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def build_training_model(self):\n",
    "        self.encoder_input = self.encoder.encoder_input\n",
    "        self.encoder_embed = self.encoder.encoder_embed\n",
    "        self.decoder_input = self.decoder.decoder_input\n",
    "        self.decoder_embed = self.decoder.decoder_embed\n",
    "        self.decoder_output = self.decoder.decoder_output\n",
    "        \n",
    "        if self.config['hierarchical']:\n",
    "            # do something\n",
    "            pass\n",
    "        else:\n",
    "            self.training_model = Model([self.encoder_input, self.decoder_input], self.decoder_output)\n",
    "    \n",
    "    def build_inference_model(self):\n",
    "        # grab some important hyperparameters\n",
    "        hidden_dim = self.config['encoding-layer-width']\n",
    "        recurrent_unit = self.config['recurrent-unit-type']\n",
    "        \n",
    "        # build the encoder model\n",
    "        self.inference_encoder = Model(self.encoder.encoder_input, self.encoder.encoder_hidden_state)\n",
    "    \n",
    "        decoder_hidden_state_input = None\n",
    "        decoder_hidden_state_output = None\n",
    "        decoder_output = None\n",
    "        # build the decoder model\n",
    "        if recurrent_unit == 'lstm':\n",
    "            decoder_hidden_state_input_h = Input(shape=(hidden_dim,))\n",
    "            decoder_hidden_state_input_c = Input(shape=(hidden_dim,))\n",
    "            decoder_hidden_state_input = [decoder_hidden_state_input_h, decoder_hidden_state_input_c]\n",
    "            # take in the regular inputs, condition on the hidden state\n",
    "            _, decoder_state_h, decoder_state_c = self.decoder.decoder_rnn(self.decoder_embed,\n",
    "                                                                           initial_state=decoder_hidden_state_input)\n",
    "            decoder_hidden_state_output = [decoder_state_h, decoder_state_c]\n",
    "        elif recurrent_unit == 'gru':\n",
    "            decoder_hidden_state_input = [Input(shape=(hidden_dim,))]\n",
    "            # take in the regular inputs, condition on the hidden state\n",
    "            decoder_output, hidden_state = self.decoder.decoder_rnn(self.decoder_embed,\n",
    "                                                                    initial_state=decoder_hidden_state_input)\n",
    "            decoder_hidden_state_output = [hidden_state]\n",
    "        else:\n",
    "            raise Exception('Invalid recurrent unit type: {}'.format(recurrent_unit))\n",
    "            \n",
    "        decoder_output = self.decoder.decoder_dense(decoder_output)\n",
    "        self.decoder_model = Model([self.decoder_input] + decoder_hidden_state_input,\n",
    "                                   [decoder_output] + decoder_hidden_state_output)\n",
    "    \n",
    "    def fit(self):\n",
    "        # grab some hyperparameters from our config\n",
    "        optimizer = self.config['optimizer']\n",
    "        loss = self.config['loss']\n",
    "        batch_size = self.config['batch-size']\n",
    "        num_epochs = self.config['num-epochs']\n",
    "        validation_split = self.config['validation-split']\n",
    "        \n",
    "        # grab the training and validation data\n",
    "        encoder_x = self.data.train.encoder_x\n",
    "        decoder_x = self.data.train.decoder_x\n",
    "        decoder_y = self.data.train.decoder_y_ohe\n",
    "        \n",
    "        self.training_model.compile(optimizer=optimizer, loss=loss)\n",
    "        self.training_model.fit([encoder_x, decoder_x], decoder_y,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=num_epochs,\n",
    "                                validation_split=validation_split)\n",
    "        \n",
    "        self.save_models()\n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Take in an integer-vectorized (i.e., index) vector, and predict the maximally\n",
    "        likely response, returning it as an integer-vectorized (i.e., index) vector.\n",
    "        \"\"\"\n",
    "        recurrent_unit = self.config['recurrent-unit-type']\n",
    "        \n",
    "        # encode the input seq into a context vector\n",
    "        if recurrent_unit == 'lstm':\n",
    "            context_state = self.encoder_model.predict(np.array(x))\n",
    "        elif recurrent_unit == 'gru':\n",
    "            hidden_state = self.encoder_model.predict(np.array(x))\n",
    "            context_state = [hidden_state]\n",
    "        else:\n",
    "            raise Exception('Invalid recurrent unit type: {}'.format(recurrent_unit))\n",
    "        \n",
    "        # create an empty target sequence, seeded with the start character\n",
    "        y = self.data.vectorize_utterance([self.data.start])\n",
    "        response = []\n",
    "        \n",
    "        # i = 0\n",
    "        while True:\n",
    "            \n",
    "            # decode the current sequence + current context into a\n",
    "            # conditional distribution over next token:\n",
    "            output_token_probs = None\n",
    "            if recurrent_unit == 'lstm':\n",
    "                output_token_probs, h, c = self.decoder_model.predict([y] + context_state)\n",
    "                context_state = [h, c]\n",
    "            elif recurrent_unit == 'gru':\n",
    "                output_token_probs, hidden_state = self.decoder_model.predict([y] + context_state)\n",
    "                context_state = [hidden_state]\n",
    "            else:\n",
    "                raise Exception('Invalid recurrent unit type: {}'.format(recurrent_unit))\n",
    "            \n",
    "            # sample a token from the output distribution (currently using maximum-likelihoo -- i.e., argmax)\n",
    "            sampled_token = np.argmax(output_token_probs[0, -1, :])\n",
    "            \n",
    "            # add the sampled token to our output string\n",
    "            response += [sampled_token]\n",
    "            \n",
    "            # exit condition: either we've\n",
    "            # - hit the max length (self.data.output_max_len), or\n",
    "            # - decoded a stop token ('\\n')\n",
    "            if (sampled_token == self.data.ie.transform([self.data.stop]) or \n",
    "                len(response) >= self.data.max_utterance_length):\n",
    "                break\n",
    "                \n",
    "            # update the np array (target seq)\n",
    "            y = np.array([sampled_token]) # np.concatenate((y, [sampled_token]))\n",
    "            \n",
    "        return response\n",
    "    \n",
    "    def save_models():\n",
    "        name = self.config['model-name']\n",
    "        if name == None:\n",
    "            name = 'model'\n",
    "        \n",
    "        self.training_model.save(name + '_train')\n",
    "        self.encoder_model.save(name + '_inference_encoder')\n",
    "        self.decoder_model.save(name + '_inference_decoder')\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logger initialized\n",
      "Configuration loaded\n",
      "Preparing to process the dialogue corpus ...\n",
      "Loading the dataset ...\n",
      "Filtering out long samples ...\n",
      "Initializing vocabulary ...\n",
      "Splitting the corpus into train/test subsets ...\n",
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "Recording sequence lengths ...\n",
      "Initializing the encoders ...\n",
      "Vectorizing the dialogues (this may take a while) ...\n",
      "Padding the dialogues ...\n",
      "Padding the dialogues ...\n",
      "Corpus succesfully loaded! Ready for training.\n"
     ]
    }
   ],
   "source": [
    "data = DialogueCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to predict x='[445 458 157  22]' of type=<class 'numpy.ndarray'>\n",
      "i because because because because n't kiss two thirty a.m. a.m. a.m. dell dell night dressed dressed dressed dressed dressed dressed the the dressed the dressed the dressed dressed ' the the dressed dressed dressed\n",
      "> What did you say?\n",
      "Attempting to predict x='[443 112 464 344  22]' of type=<class 'numpy.ndarray'>\n",
      "i because because because because n't n't kiss two thirty a.m. a.m. dell dell night night dressed dressed dressed dressed dressed the the the dressed the dressed the dressed ' the ' the dressed dressed\n",
      "> Doesn't want you thinking too much, huh?\n",
      "Attempting to predict x='[122 273 432 464 397 408 270   9 204  22]' of type=<class 'numpy.ndarray'>\n",
      "i because because because n't n't kiss two thirty a.m. a.m. dell dell dell night dressed dressed dressed dressed dressed dressed the dressed the the dressed the dressed dressed ' the the dressed dressed dressed\n",
      "> #exit\n"
     ]
    }
   ],
   "source": [
    "convo.converse(\"Where ye from?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
